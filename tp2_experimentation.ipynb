{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63a40c4",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Entrenamiento y evaluación de modelos #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d49fdde",
   "metadata": {},
   "source": [
    "## 1. Métrica ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e2012",
   "metadata": {},
   "source": [
    "Las métricas que vamos a utilizar son **F-SCORE** y además **Re-Call**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3751a3b",
   "metadata": {},
   "source": [
    "### Por qué F-SCORE? ###\n",
    "La misma consiste en combinar precission y recall. Los valores estan cerca de 1, cuando precissión y recall son buenos, en cambio, F-SCORE comienza a caer si uno de los dos cae."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd0003",
   "metadata": {},
   "source": [
    "### Por qué Re-Call? ###\n",
    "Re-Call nos permite medir que no se nos escapen interesados a las tarjetas de crédito, y en caso que NO esté interesado, el rechazo de la tarjeta, no afecta al negocio. En cambio si se escapa un caso de un cliente con interés, la empresa perdería la posibilidad de generar ingresos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e06fb",
   "metadata": {},
   "source": [
    "## Librerías ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "import keras\n",
    "import h5py\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pytz\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# One Hot Encoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer, QuantileTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import datasets\n",
    "import plotly.express as px \n",
    "pd.set_option('display.float_format',lambda x:'%.0f'% x) #Sacar notación científica en pandas\n",
    "pd.options.display.max_columns = 0\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": [\"serif\"],\n",
    "    \"font.sans-serif\": [\"Roboto\"],\n",
    "    \"font.size\": 9,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"xtick.labelsize\": 11,\n",
    "    \"ytick.labelsize\": 11,\n",
    "    \"legend.fontsize\": 11,\n",
    "    'figure.figsize': (15.0, 4.0),\n",
    "    'axes.grid': False,\n",
    "    'axes.spines.left': True,\n",
    "    'axes.spines.right': True,\n",
    "    'axes.spines.top': True,\n",
    "    'axes.spines.bottom': True,\n",
    "})\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d54b17",
   "metadata": {},
   "source": [
    "## Train ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TC = pd.read_csv('train.csv')\n",
    "\n",
    "BETTER_COLUMN_NAMES = {\n",
    "    'ID': 'id',\n",
    "    'Gender': 'sexo',\n",
    "    'Age': 'edad',\n",
    "    'Region_Code': 'codigo_region',\n",
    "    'Occupation': 'ocupacion',\n",
    "    'Channel_Code': 'codigo_canal',\n",
    "    'Vintage': 'antiguedad',\n",
    "    'Credit_Product': 'tiene_producto_credito_activo',\n",
    "    'Avg_Account_Balance': 'saldo_promedio_cuenta',\n",
    "    'Is_Active': 'es_activo',\n",
    "    'Is_Lead': 'esta_interesado',\n",
    "}\n",
    "data_TC.rename(columns=BETTER_COLUMN_NAMES, inplace=True)\n",
    "\n",
    "data_TC.set_index('id', inplace=True)\n",
    "\n",
    "DATA_MODIFICADA = data_TC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583492c6",
   "metadata": {},
   "source": [
    "## 2. Técnica feature engineering ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c173aa",
   "metadata": {},
   "source": [
    "- **Técnica Quantile Transformation(edades)** Utilizaremos esta técnica para llevar los datos a una distribución uniforme o normal, generando robustez para los outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6701224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "x = DATA_MODIFICADA.edad\n",
    "\n",
    "fig = make_subplots(rows=3, cols=2)\n",
    "\n",
    "trace0 = go.Histogram(x=x, nbinsx=100)\n",
    "trace1 = go.Histogram(x=x, nbinsx=5)\n",
    "trace2 = go.Histogram(x=x, nbinsx = 8)\n",
    "trace3 = go.Histogram(x=x, nbinsx = 10)\n",
    "trace4 = go.Histogram(x=x, nbinsx = 12)\n",
    "\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 2, 1)\n",
    "fig.append_trace(trace2, 2, 2)\n",
    "fig.append_trace(trace3, 3, 1)\n",
    "fig.append_trace(trace4, 3, 2)\n",
    "\n",
    "fig.show()\n",
    "#Revisar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cce790",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_quantile = 10\n",
    "DATA_MODIFICADA['Quantiles_edad'],edges = pd.qcut(x=DATA_MODIFICADA['edad'], q=number_of_quantile, labels=False, retbins=True )\n",
    "print('values of edges: ' + str(edges))\n",
    "\n",
    "#Evitar Nans:\n",
    "ed = np.delete(edges, 0)\n",
    "ed = np.delete(ed, -1)\n",
    "ed = np.append(np.append([DATA_MODIFICADA.edad.min()], [ed]), [DATA_MODIFICADA.edad.max()])\n",
    "print('\\nvalues of ed: ' + str(ed))\n",
    "\n",
    "\n",
    "\n",
    "# Transform the array as an IntervalIndex\n",
    "Interval_Index = pd.IntervalIndex.from_breaks(ed,closed='right',dtype='interval[int64]')\n",
    "print('\\nvalues of Interval_Index: ' + str(Interval_Index))\n",
    "\n",
    "# Create a column displaying the interval\n",
    "DATA_MODIFICADA['quantile_interval'] = pd.cut(DATA_MODIFICADA['edad'], bins=Interval_Index)\n",
    "\n",
    "dict_inter_quantile = pd.Series(DATA_MODIFICADA['quantile_interval'].unique().sort_values(ascending=False), name='interval').reset_index()\n",
    "dict_inter_quantile.columns = ['Quantiles_edad', 'quantile_interval']\n",
    "dict_inter_quantile = dict_inter_quantile.set_index('quantile_interval')\n",
    "\n",
    "DATA_MODIFICADA.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in DATA_MODIFICADA.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e664df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.tips()\n",
    "\n",
    "fig = px.histogram(DATA_MODIFICADA, x=\"edad\",color=\"esta_interesado\", marginal = 'box',title='Distribución sin quantiles')\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(DATA_MODIFICADA,x=\"Quantiles_edad\",color=\"esta_interesado\", marginal = 'box',title='Distribución por quantiles')\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2134efd",
   "metadata": {},
   "source": [
    "- **Técnica Quantile Transformation(saldo promedio de cuenta)** Utilizaremos esta técnica para llevar los datos a una distribución uniforme o normal, generando robustez para los outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19647d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_quantile = 20\n",
    "DATA_MODIFICADA['Quantiles_saldos'],edges = pd.qcut(x=DATA_MODIFICADA['saldo_promedio_cuenta'], q=number_of_quantile, labels=False, retbins=True )\n",
    "print('values of edges: ' + str(edges))\n",
    "\n",
    "#Evitar Nans:\n",
    "ed = np.delete(edges, 0)\n",
    "ed = np.delete(ed, -1)\n",
    "ed = np.append(np.append([DATA_MODIFICADA.saldo_promedio_cuenta.min()], [ed]), [DATA_MODIFICADA.saldo_promedio_cuenta.max()])\n",
    "print('\\nvalues of ed: ' + str(ed))\n",
    "\n",
    "# Transform the array as an IntervalIndex\n",
    "Interval_Index = pd.IntervalIndex.from_breaks(ed,closed='right',dtype='interval[int64]')\n",
    "print('\\nvalues of Interval_Index: ' + str(Interval_Index))\n",
    "\n",
    "# Create a column displaying the interval\n",
    "DATA_MODIFICADA['Intervalos saldos'] = pd.cut(DATA_MODIFICADA['saldo_promedio_cuenta'], bins=Interval_Index)\n",
    "\n",
    "dict_inter_quantile = pd.Series(DATA_MODIFICADA['Intervalos saldos'].unique().sort_values(ascending=False), name='interval').reset_index()\n",
    "dict_inter_quantile.columns = ['Quantiles_saldos', 'Intervalos saldos']\n",
    "dict_inter_quantile = dict_inter_quantile.set_index('Intervalos saldos')\n",
    "\n",
    "DATA_MODIFICADA.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33094557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.tips()\n",
    "\n",
    "fig = px.histogram(DATA_MODIFICADA, x=\"saldo_promedio_cuenta\",color=\"esta_interesado\", marginal = 'box',title='Distribución sin quantiles')\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(DATA_MODIFICADA,x=\"Quantiles_saldos\",color=\"esta_interesado\", marginal = 'box',title='Distribución por quantiles')\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55296fc0",
   "metadata": {},
   "source": [
    "- **Técnica Quantile Transformation(antiguedad)** Utilizaremos esta técnica para llevar los datos a una distribución uniforme o normal, generando robustez para los outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec766661",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_quantile = 5\n",
    "DATA_MODIFICADA['Quantiles_antiguedad'],edges = pd.qcut(x=data_TC['antiguedad'], q=number_of_quantile, labels=False, retbins=True )\n",
    "print('values of edges: ' + str(edges))\n",
    "\n",
    "#Evitar Nans:\n",
    "ed = np.delete(edges, 0)\n",
    "ed = np.delete(ed, -1)\n",
    "ed = np.append(np.append([data_TC.antiguedad.min()], [ed]), [data_TC.antiguedad.max()])\n",
    "print('\\nvalues of ed: ' + str(ed))\n",
    "\n",
    "# Transform the array as an IntervalIndex\n",
    "Interval_Index = pd.IntervalIndex.from_breaks(ed,closed='right',dtype='interval[int64]')\n",
    "print('\\nvalues of Interval_Index: ' + str(Interval_Index))\n",
    "\n",
    "# Create a column displaying the interval\n",
    "DATA_MODIFICADA['Intervalos antiguedad'] = pd.cut(DATA_MODIFICADA['antiguedad'], bins=Interval_Index)\n",
    "\n",
    "dict_inter_quantile = pd.Series(DATA_MODIFICADA['Intervalos antiguedad'].unique().sort_values(ascending=False), name='interval').reset_index()\n",
    "dict_inter_quantile.columns = ['Quantiles_antiguedad', 'Intervalos antiguedad']\n",
    "dict_inter_quantile = dict_inter_quantile.set_index('Intervalos antiguedad')\n",
    "\n",
    "DATA_MODIFICADA.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78526001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.tips()\n",
    "\n",
    "fig = px.histogram(DATA_MODIFICADA, x=\"antiguedad\",color=\"esta_interesado\", marginal = 'box',title='Distribución sin quantiles')\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(DATA_MODIFICADA,x=\"Quantiles_antiguedad\",color=\"esta_interesado\", marginal = 'box',title='Distribución por quantiles')\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd152cd",
   "metadata": {},
   "source": [
    "## 3. Qué modelos vamos a evaluar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b4640",
   "metadata": {},
   "source": [
    "- Gradient Boosting\n",
    "- Regresión Logística\n",
    "- Ver otros...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90879912",
   "metadata": {},
   "source": [
    "#### Preparación Datos ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in DATA_MODIFICADA.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MODIFICADA.shape #Ver filas y columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61fa639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columnas que no vamos a utilizar:\n",
    "DATA_MODIFICADA = DATA_MODIFICADA.drop(['edad', 'antiguedad', 'saldo_promedio_cuenta', 'quantile_interval','Intervalos saldos', 'Intervalos antiguedad'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MODIFICADA.shape #Ver filas y columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db798494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_MODIFICADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcbd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in DATA_MODIFICADA.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8f914",
   "metadata": {},
   "source": [
    "## División del data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esto capaz nos convenga hacerlo en el mapper con sklearn\n",
    "# Esto es para eliminar los nulos\n",
    "#DATA_MODIFICADA = DATA_MODIFICADA[DATA_MODIFICADA['tiene_producto_credito_activo'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08868e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 60% train, 20% test, 20% validation\n",
    "train, not_train = train_test_split(DATA_MODIFICADA, test_size=0.4, random_state=42)\n",
    "validation, test = train_test_split(not_train, test_size=0.5, random_state=42)\n",
    "\n",
    "train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca5d5c",
   "metadata": {},
   "source": [
    "##### Prepando el Mapper: #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec618f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in DATA_MODIFICADA.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad28f1",
   "metadata": {},
   "source": [
    "# Mapper SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb585e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    (['sexo'], [LabelBinarizer()]), \n",
    "    (['codigo_region'], [OneHotEncoder()]),\n",
    "    (['ocupacion'], [OneHotEncoder()]),\n",
    "    (['codigo_canal'], [OneHotEncoder()]),\n",
    "    (['tiene_producto_credito_activo'], [SimpleImputer(strategy='most_frequent'), \n",
    "                                         LabelBinarizer()]),\n",
    "    (['es_activo'], [LabelBinarizer()]),\n",
    "    (['Quantiles_edad'], [StandardScaler()]),\n",
    "    (['Quantiles_saldos'], [StandardScaler()]),\n",
    "    (['Quantiles_antiguedad'], [StandardScaler()])\n",
    "], df_out=True) # df_out=True → Es lo que muestra el nombre de la columna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a77af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample transformado\n",
    "mapper.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72569ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(mapper.fit_transform(train), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2903b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de los faetures\n",
    "mapper.transformed_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ad8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample transformado\n",
    "mapper.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe1f6f",
   "metadata": {},
   "source": [
    "# Pipeline SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cdbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_si = Pipeline([\n",
    "#     ('imputer', IterativeImputer(random_state=94)),\n",
    "#     ('mapper', mapper),\n",
    "# ])\n",
    "# # Lo entrenamos con train\n",
    "# pipe_si.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a201ef",
   "metadata": {},
   "source": [
    "#### Programemos una función para evaluar un modelo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e659746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def evaluate_model(model, set_names=('train', 'validation'), title='', show_cm=True):\n",
    "    if title:\n",
    "        display(title)\n",
    "        \n",
    "    final_metrics = defaultdict(list)\n",
    "    \n",
    "    if show_cm:\n",
    "        fig, axis = plt.subplots(1, len(set_names), sharey=True, figsize=(15, 3))\n",
    "    \n",
    "    for i, set_name in enumerate(set_names):\n",
    "        assert set_name in ['train', 'validation', 'test']\n",
    "        set_data = globals()[set_name]  # <- hack feo...\n",
    "\n",
    "        y = set_data.esta_interesado\n",
    "        y_pred = model.predict(set_data)\n",
    "        final_metrics['Accuracy'].append(metrics.accuracy_score(y, y_pred))\n",
    "        final_metrics['Precision'].append(metrics.precision_score(y, y_pred))\n",
    "        final_metrics['Recall'].append(metrics.recall_score(y, y_pred))\n",
    "        final_metrics['F1'].append(metrics.f1_score(y, y_pred))\n",
    "        \n",
    "        if show_cm:\n",
    "            ax = axis[i]\n",
    "            sns.heatmap(metrics.confusion_matrix(y, y_pred), ax=ax, cmap='Blues', annot=True, fmt='.0f', cbar=False)\n",
    "\n",
    "            ax.set_title(set_name)\n",
    "            ax.xaxis.set_ticklabels(['no esta interesado', 'esta interesado'])\n",
    "            ax.yaxis.set_ticklabels(['no esta interesado', 'esta interesado'])\n",
    "            ax.set_xlabel('Predicted class')\n",
    "            ax.set_ylabel('True class')\n",
    "\n",
    "        \n",
    "    display(pd.DataFrame(final_metrics, index=set_names))\n",
    "    if show_cm:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd6d83",
   "metadata": {},
   "source": [
    "#### Gradient Boosting ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b395c00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbc_model = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=94)),\n",
    "])\n",
    "\n",
    "gbc_model.fit(train, train.esta_interesado)\n",
    "\n",
    "evaluate_model(gbc_model, title='Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227114cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe615cb",
   "metadata": {},
   "source": [
    "#### Regresión Logística ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2432e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "regresion_logistica = LogisticRegression()\n",
    "#regresion_logistica.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', LogisticRegression(random_state=94)),\n",
    "])\n",
    "\n",
    "lr_model.fit(train, train.esta_interesado)\n",
    "\n",
    "y_pred = lr_model.predict(validation)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30109b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(validation.esta_interesado, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc2cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d496fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61dab8ab",
   "metadata": {},
   "source": [
    "# Mapper En progreso (eliminar columna o probar con otros imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a3a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper_ii = DataFrameMapper([\n",
    "#     ('clmn_drpr', 'drop', ['tiene_producto_credito_activo'])])\n",
    "#     (['sexo'], [LabelBinarizer()]), \n",
    "#     (['codigo_region'], [OneHotEncoder()]),\n",
    "#     (['ocupacion'], [OneHotEncoder()]),\n",
    "#     (['codigo_canal'], [OneHotEncoder()]),\n",
    "#     (['tiene_producto_credito_activo'], [KNNImputer(n_neighbors=10), \n",
    "#                                          LabelBinarizer()]),\n",
    "#     (['es_activo'], [LabelBinarizer()]),\n",
    "#     (['Quantiles_edad'], [StandardScaler()]),\n",
    "#     (['Quantiles_saldos'], [StandardScaler()]),\n",
    "#     (['Quantiles_antiguedad'], [StandardScaler()])\n",
    "# ], df_out=True, default=False) # df_out=True → Es lo que muestra el nombre de la columna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper_ii = DataFrameMapper(\n",
    "#     drop_cols=['tiene_producto_credito_activo'],\n",
    "#     [\n",
    "#     (['sexo'], [LabelBinarizer()]), \n",
    "#     (['codigo_region'], [OneHotEncoder()]),\n",
    "#     (['ocupacion'], [OneHotEncoder()]),\n",
    "#     (['codigo_canal'], [OneHotEncoder()]),\n",
    "#     (['es_activo'], [LabelBinarizer()]),\n",
    "#     (['Quantiles_edad'], [StandardScaler()]),\n",
    "#     (['Quantiles_saldos'], [StandardScaler()]),\n",
    "#     (['Quantiles_antiguedad'], [StandardScaler()])\n",
    "# ], df_out=True, default=False) # df_out=True → Es lo que muestra el nombre de la columna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e68cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample transformado\n",
    "mapper_ii.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6394cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(mapper_ii.fit_transform(train), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de los faetures\n",
    "mapper.transformed_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample transformado\n",
    "mapper.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd30d4",
   "metadata": {},
   "source": [
    "# Pipeline SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bcdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_si = Pipeline([\n",
    "#     ('imputer', IterativeImputer(random_state=94)),\n",
    "#     ('mapper', mapper),\n",
    "# ])\n",
    "# # Lo entrenamos con train\n",
    "# pipe_si.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5fba1",
   "metadata": {},
   "source": [
    "#### Programemos una función para evaluar un modelo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def evaluate_model(model, set_names=('train', 'validation'), title='', show_cm=True):\n",
    "    if title:\n",
    "        display(title)\n",
    "        \n",
    "    final_metrics = defaultdict(list)\n",
    "    \n",
    "    if show_cm:\n",
    "        fig, axis = plt.subplots(1, len(set_names), sharey=True, figsize=(15, 3))\n",
    "    \n",
    "    for i, set_name in enumerate(set_names):\n",
    "        assert set_name in ['train', 'validation', 'test']\n",
    "        set_data = globals()[set_name]  # <- hack feo...\n",
    "\n",
    "        y = set_data.esta_interesado\n",
    "        y_pred = model.predict(set_data)\n",
    "        final_metrics['Accuracy'].append(metrics.accuracy_score(y, y_pred))\n",
    "        final_metrics['Precision'].append(metrics.precision_score(y, y_pred))\n",
    "        final_metrics['Recall'].append(metrics.recall_score(y, y_pred))\n",
    "        final_metrics['F1'].append(metrics.f1_score(y, y_pred))\n",
    "        \n",
    "        if show_cm:\n",
    "            ax = axis[i]\n",
    "            sns.heatmap(metrics.confusion_matrix(y, y_pred), ax=ax, cmap='Blues', annot=True, fmt='.0f', cbar=False)\n",
    "\n",
    "            ax.set_title(set_name)\n",
    "            ax.xaxis.set_ticklabels(['no esta interesado', 'esta interesado'])\n",
    "            ax.yaxis.set_ticklabels(['no esta interesado', 'esta interesado'])\n",
    "            ax.set_xlabel('Predicted class')\n",
    "            ax.set_ylabel('True class')\n",
    "\n",
    "        \n",
    "    display(pd.DataFrame(final_metrics, index=set_names))\n",
    "    if show_cm:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6defaa1",
   "metadata": {},
   "source": [
    "#### Gradient Boosting ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a257f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbc_model = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=94)),\n",
    "])\n",
    "\n",
    "gbc_model.fit(train, train.esta_interesado)\n",
    "\n",
    "evaluate_model(gbc_model, title='Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f56a2ac",
   "metadata": {},
   "source": [
    "#### Regresión Logística ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd489123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "regresion_logistica = LogisticRegression()\n",
    "#regresion_logistica.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', LogisticRegression(random_state=94)),\n",
    "])\n",
    "\n",
    "lr_model.fit(train, train.esta_interesado)\n",
    "\n",
    "y_pred = lr_model.predict(validation)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafe474",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(validation.esta_interesado, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80218f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
